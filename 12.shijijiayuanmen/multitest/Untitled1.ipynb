{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='www.jiayuan.com', port=80): Max retries exceeded with url: /164432867 (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000001A6D8517908>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 150\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <requests.packages.urllib3.connection.HTTPConnection object at 0x000001A6D8517908>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    648\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 649\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    650\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='www.jiayuan.com', port=80): Max retries exceeded with url: /164432867 (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000001A6D8517908>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b2afa99c82e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m \u001b[0mrun_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-b2afa99c82e1>\u001b[0m in \u001b[0;36mrun_task\u001b[1;34m(start_num, store_name)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"被禁止了！\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    516\u001b[0m         }\n\u001b[0;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    500\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='www.jiayuan.com', port=80): Max retries exceeded with url: /164432867 (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000001A6D8517908>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def get_location_id_name(page,dic):\n",
    "        pattern = re.compile('浙江(\\w+)交友_(.+)（佳缘ID:(\\d+)）的个人资料_世纪佳缘交友网</title>',re.U | re.S)\n",
    "        result = pattern.search(page)\n",
    "        if result is not None:\n",
    "            dic[\"nickname\"] = result.group(2)\n",
    "            dic[\"id\"] = result.group(3)\n",
    "            dic[\"location\"] = result.group(1)\n",
    "            return dic\n",
    "    \n",
    "def is_membership(page,dic):\n",
    "    pattern = re.compile('<span class=\\\"member_dj\\\">(.*?)</span>', re.S)\n",
    "    result = pattern.search(page)\n",
    "    if result is not None:\n",
    "        if \"普通会员\" in result.group(0):\n",
    "            dic[\"membership\"] = \"普通会员\"\n",
    "        else:\n",
    "            dic[\"membership\"] = \"高级会员\"\n",
    "    return dic\n",
    "\n",
    "def get_brief_info(page,dic):\n",
    "    pattern = re.compile('<h6 class=\\\"member_name\\\">(.*?)<', re.S)\n",
    "    result = pattern.search(page)\n",
    "    if result is not None:\n",
    "        brief_info = result.group(1)\n",
    "        dic[\"age\"]= brief_info.split(\"，\")[0]\n",
    "        dic[\"marriaged\"] =brief_info.split(\"，\")[1]\n",
    "    return dic\n",
    "\n",
    "def get_basic_info(soup,dic): #基本信息\n",
    "    try:\n",
    "        list_info = soup.find_all('ul', {'class':\"member_info_list\"})[0].find_all('em')\n",
    "        if len(list_info)>0:\n",
    "            dic[\"education\"] = list_info[0].text\n",
    "            dic[\"height\"] = list_info[1].text\n",
    "            dic[\"car\"] = list_info[2].text\n",
    "            dic[\"salary\"] = list_info[3].text\n",
    "            dic[\"house\"] = list_info[4].text\n",
    "            dic[\"weight\"] = list_info[5].text\n",
    "            dic[\"constellation\"] = list_info[6].text\n",
    "            dic[\"ethnic\"] = list_info[7].text\n",
    "            dic[\"shengxiao\"] = list_info[8].text\n",
    "            dic[\"blood\"] = list_info[9].text\n",
    "            return dic\n",
    "    except:\n",
    "        return dic\n",
    "        #return education,height,car,salary,house,weight,constellation,ethnic,shengxiao,blood\n",
    "    #else:\n",
    "     #   return None,None,None,None,None,None,None,None,None,None,\n",
    "        \n",
    "def js_info(soup,dic): #择偶要求,用soup\n",
    "    try:\n",
    "        js_list = soup.find_all('ul', {'class':\"js_list\"})[0].find_all('div')\n",
    "        if len(js_list)>0:\n",
    "            dic[\"js_age\"] = js_list[0].text.replace(\" \",\"\")\n",
    "            dic[\"js_height\"] = js_list[1].text.replace(\" \",\"\")\n",
    "            dic[\"js_ethnic\"] = js_list[2].text.replace(\" \",\"\")\n",
    "            dic[\"js_education\"] = js_list[3].text.replace(\" \",\"\")\n",
    "            dic[\"js_photo\"] = js_list[4].text.replace(\"\\xa0*\",\"\")\n",
    "            dic[\"js_marriaged\"] = js_list[5].text.replace(\" \",\"\")\n",
    "            dic[\"js_location\"] = js_list[6].text.replace(\" \",\"\").replace(\"\\xa0*\",\"\")\n",
    "            dic[\"js_member\"] = js_list[7].text.replace(\" \",\"\")\n",
    "            return dic\n",
    "    except:\n",
    "        return dic\n",
    "    \n",
    "\n",
    "def run_task(start_num,store_name):\n",
    "\n",
    "    #file_name = input(\"输入id文档地址：\")\n",
    "    input_name = \"quzhou.csv\"\n",
    "    output_name = store_name +  \"到\"+ str(start_num+300) + \".csv\"    \n",
    "    id_list = pd.read_csv(input_name)\n",
    "    final_list = []\n",
    "    cookies = {}\n",
    "    #raw_cookies = input(\"enter the cookies：\")\n",
    "    raw_cookies = \"is_searchv2=1; view_m=1; looyu_id=a1ef73a295e9f7b14b703723e649126eb2_47617%3A1; ip_loc=31; PHPSESSID=253b4edda4e97c38807dde9af958996d; user_access=1; save_jy_login_name=13586720652; upt=0IqmEsMJE-RmWnD5c8PNtfovpfnfID8BHn8CdFEkyL5iTrZg3%2Ar240QXcYre%2AnXwGsNcRvSB9AqpD7uJ9zM.; SESSION_HASH=7494a78808b89a89615c79d5ec1fdac88683ff22; last_login_time=1508087252; user_attr=000000; main_search:168337151=%7C%7C%7C00; pclog=%7B%22168337151%22%3A%221508087255229%7C1%7C0%22%7D; stadate1=167337151; myloc=33%7C3301; myage=24; PROFILE=168337151%3A%25E4%25BD%25B3%25E7%25BC%2598%25E5%25BE%2581%25E5%25A9%259A%3Am%3Aimages1.jyimg.com%2Fw4%2Fglobal%2Fi%3A0%3A%3A1%3Azwzp_m.jpg%3A2%3A1%3A50%3A10; mysex=m; myuid=167337151; myincome=10; RAW_HASH=YLjTqQPvP7hBa9cyeAmv0wsQkviFKuMEURlNKsYx0bVi9G93Hkl2RelPSTRoKwBtvgan%2AWC-MXJuvlSYfy8XnXPuDyUmxFzOiYwOOUJHiiJA754.; COMMON_HASH=83e9417e38e2d65c04d54e7700bbf6b2; REG_REF_URL=; IM_CON=%7B%22IM_TM%22%3A1508089825056%2C%22IM_SN%22%3A3%7D; IM_S=%7B%22IM_CID%22%3A1579942%2C%22m%22%3A0%2C%22f%22%3A0%2C%22omc%22%3A0%2C%22svc%22%3A%7B%22code%22%3A0%2C%22nps%22%3A0%2C%22unread_count%22%3A%220%22%2C%22ocu%22%3A0%2C%22ppc%22%3A0%2C%22jpc%22%3A0%2C%22regt%22%3A%221505057605%22%2C%22using%22%3A%22%22%2C%22user_type%22%3A%2210%22%2C%22uid%22%3A168337151%7D%7D; IM_M=%5B%5D; IM_CS=2; IM_ID=9; pop_time=1508090200875; IM_TK=1508090533524\"\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
    "    }\n",
    "    for line in raw_cookies.split(';'):\n",
    "        key,value=line.split('=',1)#1代表只分一次，得到两个数据\n",
    "        cookies[key[1:]]=value\n",
    "\n",
    "    print(1)\n",
    "    count = 0\n",
    "    #if start_num == 1000:\n",
    "    #    loop_list = id_list[\"id\"][start_num:]\n",
    "    #else:\n",
    "    #    loop_list = id_list[\"id\"][start_num:start_num+201]\n",
    "    \n",
    "    if start_num == 1500:\n",
    "        end_num = 1555\n",
    "    for i in id_list[\"id\"][start_num:]:\n",
    "        status = False\n",
    "        count = count + 1\n",
    "        dic ={}\n",
    "        search_url = \"http://www.jiayuan.com/\"+ str(i)\n",
    "\n",
    "        while(status == False):\n",
    "            r= requests.get(search_url,cookies=cookies,headers=headers)\n",
    "            if r.status_code != 200:\n",
    "                print(\"被禁止了！\")\n",
    "                time.sleep(60)\n",
    "            else:\n",
    "                status = True\n",
    "\n",
    "        soup = BeautifulSoup(r.content,\"html.parser\")\n",
    "        try:\n",
    "            dic = get_location_id_name(str(soup),dic)\n",
    "            dic = is_membership(str(soup),dic)\n",
    "            dic = get_brief_info(str(soup),dic)\n",
    "            dic = get_basic_info(soup,dic)\n",
    "            dic = js_info(soup,dic)\n",
    "            if dic is not None:\n",
    "                final_list.append(dic)\n",
    "                df = pd.DataFrame(final_list)\n",
    "                df.to_csv(output_name, encoding='utf-8')\n",
    "            print(\"抓取的是\"+ str(start_num) + \"到\" + str(start_num+1400) + \"的用户\")\n",
    "            print(\"第\"+ str(len(final_list)+start_num)+ \"用户的信息抓取完毕!\" + \"实际抓取的是第\"+ str(count+start_num)+\"个用户\")\n",
    "        except:\n",
    "            print(\"不是浙江的！\")\n",
    "            print(i)\n",
    "            pass\n",
    "\n",
    "run_task(0,\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-process(es) done.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import test\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(processes=5)\n",
    "    result = []\n",
    "    for i in [0,300,600,900,1200,1255]:\n",
    "        result.append(pool.apply_async(test.run_task, (i,str(i) )))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print (\"Sub-process(es) done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def get_location_id_name(page,dic):\n",
    "        pattern = re.compile('浙江(\\w+)交友_(.+)（佳缘ID:(\\d+)）的个人资料_世纪佳缘交友网</title>',re.U | re.S)\n",
    "        result = pattern.search(page)\n",
    "        if result is not None:\n",
    "            dic[\"nickname\"] = result.group(2)\n",
    "            dic[\"id\"] = result.group(3)\n",
    "            dic[\"location\"] = result.group(1)\n",
    "            return dic\n",
    "    \n",
    "def is_membership(page,dic):\n",
    "    pattern = re.compile('<span class=\\\"member_dj\\\">(.*?)</span>', re.S)\n",
    "    result = pattern.search(page)\n",
    "    if result is not None:\n",
    "        if \"普通会员\" in result.group(0):\n",
    "            dic[\"membership\"] = \"普通会员\"\n",
    "        else:\n",
    "            dic[\"membership\"] = \"高级会员\"\n",
    "    return dic\n",
    "\n",
    "def get_brief_info(page,dic):\n",
    "    pattern = re.compile('<h6 class=\\\"member_name\\\">(.*?)<', re.S)\n",
    "    result = pattern.search(page)\n",
    "    if result is not None:\n",
    "        brief_info = result.group(1)\n",
    "        dic[\"age\"]= brief_info.split(\"，\")[0]\n",
    "        dic[\"marriaged\"] =brief_info.split(\"，\")[1]\n",
    "    return dic\n",
    "\n",
    "def get_basic_info(soup,dic): #基本信息\n",
    "    try:\n",
    "        list_info = soup.find_all('ul', {'class':\"member_info_list\"})[0].find_all('em')\n",
    "        print(list_info)\n",
    "        if len(list_info)>0:\n",
    "            dic[\"education\"] = list_info[0].text\n",
    "            dic[\"height\"] = list_info[1].text\n",
    "            dic[\"car\"] = list_info[2].text\n",
    "            dic[\"salary\"] = list_info[3].text\n",
    "            dic[\"house\"] = list_info[4].text\n",
    "            dic[\"weight\"] = list_info[5].text\n",
    "            dic[\"constellation\"] = list_info[6].text\n",
    "            dic[\"ethnic\"] = list_info[7].text\n",
    "            dic[\"shengxiao\"] = list_info[8].text\n",
    "            dic[\"blood\"] = list_info[9].text\n",
    "            return dic\n",
    "    except:\n",
    "        return dic\n",
    "        #return education,height,car,salary,house,weight,constellation,ethnic,shengxiao,blood\n",
    "    #else:\n",
    "     #   return None,None,None,None,None,None,None,None,None,None,\n",
    "        \n",
    "def js_info(soup,dic): #择偶要求,用soup\n",
    "    try:\n",
    "        js_list = soup.find_all('ul', {'class':\"js_list\"})[0].find_all('div')\n",
    "        print(soup)\n",
    "        if len(js_list)>0:\n",
    "            dic[\"js_age\"] = js_list[0].text.replace(\" \",\"\")\n",
    "            dic[\"js_height\"] = js_list[1].text.replace(\" \",\"\")\n",
    "            dic[\"js_ethnic\"] = js_list[2].text.replace(\" \",\"\")\n",
    "            dic[\"js_education\"] = js_list[3].text.replace(\" \",\"\")\n",
    "            dic[\"js_photo\"] = js_list[4].text.replace(\"\\xa0*\",\"\")\n",
    "            dic[\"js_marriaged\"] = js_list[5].text.replace(\" \",\"\")\n",
    "            dic[\"js_location\"] = js_list[6].text.replace(\" \",\"\").replace(\"\\xa0*\",\"\")\n",
    "            dic[\"js_member\"] = js_list[7].text.replace(\" \",\"\")\n",
    "            print(dic)\n",
    "            return dic\n",
    "    except:\n",
    "        return dic\n",
    "    \n",
    "\n",
    "def run_task(start_num,store_name):\n",
    "    #file_name = input(\"输入id文档地址：\")\n",
    "    input_name = \"quzhou.csv\"\n",
    "    output_name = store_name +  \"到\"+ str(start_num+200) + \".csv\"    \n",
    "    id_list = pd.read_csv(input_name)\n",
    "    final_list = []\n",
    "    cookies = {}\n",
    "    #raw_cookies = input(\"enter the cookies：\")\n",
    "    raw_cookies = \"photo_scyd_168337151=yes; SESSION_HASH=e2d538843999fbbb33ec2339be97697bd03f0f8d; REG_REF_URL=http://login.jiayuan.com/logout2.php; user_access=1; save_jy_login_name=13586720652; sl_jumper=%26cou%3D17%26omsg%3D0%26dia%3D0%26lst%3D2017-10-15; last_login_time=1508031757; upt=0IqmEsMJE-RmWnD5c8PNtfovpfnfID8BHn8CdFEkyL5iTrZg3%2Ar240QXcYre%2AnXwGsNcRvSB9AqpD7uJ9zM.; user_attr=000000; stadate1=167337151; myloc=33%7C3301; myage=24; PROFILE=168337151%3A%25E4%25BD%25B3%25E7%25BC%2598%25E5%25BE%2581%25E5%25A9%259A%3Am%3Aimages1.jyimg.com%2Fw4%2Fglobal%2Fi%3A0%3A%3A1%3Azwzp_m.jpg%3A2%3A1%3A50%3A10; mysex=m; myuid=167337151; myincome=10; RAW_HASH=R%2AewwT3JpsK8ISa6dtuv4iZoIDkdHpI0kzepnoj-pYXNoNsL3oYJbb4lifamvIhTHa1fvGx8OqVDrHLMz2FSAgSgbJX2pyW7NqLrugQpfeiM9C0.; COMMON_HASH=83e9417e38e2d65c04d54e7700bbf6b2\"\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
    "    }\n",
    "    for line in raw_cookies.split(';'):\n",
    "        key,value=line.split('=',1)#1代表只分一次，得到两个数据\n",
    "        cookies[key[1:]]=value\n",
    "\n",
    "    print(1)\n",
    "    count = 0\n",
    "    #if start_num == 1000:\n",
    "    #    loop_list = id_list[\"id\"][start_num:]\n",
    "    #else:\n",
    "    #    loop_list = id_list[\"id\"][start_num:start_num+201]\n",
    "    \n",
    "    for i in id_list[\"id\"][start_num:2]:\n",
    "        status = False\n",
    "        count = count + 1\n",
    "        dic ={}\n",
    "        search_url = \"http://www.jiayuan.com/\"+ str(i)\n",
    "\n",
    "        while(status == False):\n",
    "            r= requests.get(search_url,cookies=cookies,headers=headers)\n",
    "            if r.status_code != 200:\n",
    "                print(\"被禁止了！\")\n",
    "                time.sleep(60)\n",
    "            else:\n",
    "                status = True\n",
    "\n",
    "        soup = BeautifulSoup(r.content,\"html.parser\")\n",
    "        try:\n",
    "            dic = get_location_id_name(str(soup),dic)\n",
    "            dic = is_membership(str(soup),dic)\n",
    "            dic = get_brief_info(str(soup),dic)\n",
    "            dic = get_basic_info(soup,dic)\n",
    "            dic = js_info(soup,dic)\n",
    "            if dic is not None:\n",
    "                final_list.append(dic)\n",
    "                df = pd.DataFrame(final_list)\n",
    "                df.to_csv(output_name, encoding='utf-8')\n",
    "            print(\"抓取的是\"+ str(start_num) + \"到\" + str(start_num+1400) + \"的用户\")\n",
    "            print(\"第\"+ str(len(final_list)+start_num)+ \"用户的信息抓取完毕!\" + \"实际抓取的是第\"+ str(count+start_num)+\"个用户\")\n",
    "        except:\n",
    "            print(\"不是浙江的！\")\n",
    "            print(i)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
